{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import featuretools as ft\n",
    "\n",
    "from woodwork.logical_types import Categorical, Boolean, Datetime, Double\n",
    "\n",
    "# from featuretools_sklearn_transformer import DFSTransformer => did not work\n",
    "from featuretools.selection import (\n",
    "    remove_highly_correlated_features,\n",
    "    remove_highly_null_features,\n",
    "    remove_single_value_features,\n",
    ")\n",
    "\n",
    "from datetime import datetime\n",
    "from uuid import uuid4\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from typing import List, Any\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "\n",
    "pd.option_context(\"max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/IBM/telco-customer-churn-on-icp4d\n",
    "URL_TO_DATA = \"https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv\"\n",
    "\n",
    "\n",
    "BACK_COUNT_DATE = datetime.fromisoformat(\"2022-01-01\")\n",
    "TEST_SIZE = 0.2\n",
    "VALID_SIZE = 0.25\n",
    "RANDOM_STATE = 42\n",
    "NUMERIC_TRANSFORMER_REPLACEMENT = \"median\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"imputer\",\n",
    "            SimpleImputer(\n",
    "                missing_values=np.nan, strategy=NUMERIC_TRANSFORMER_REPLACEMENT\n",
    "            ),\n",
    "        ),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def get_cols_by_type(\n",
    "    in_df: pd.DataFrame, types_to_search: list, exclude_ids: Boolean = True\n",
    ") -> list:\n",
    "    cols = in_df.select_dtypes(include=types_to_search).columns.to_list()\n",
    "\n",
    "    if exclude_ids:\n",
    "        return list(filter(lambda x: not x.endswith(\"ID\"), cols))\n",
    "\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ft titanic https://www.kaggle.com/code/liananapalkova/automated-feature-engineering-for-titanic-dataset/notebook\n",
    "- the dataset https://github.com/IBM/telco-customer-churn-on-icp4d/blob/master/data/Telco-Customer-Churn.csv\n",
    "- titanic https://medium.com/dataexplorations/tool-review-can-featuretools-simplify-the-process-of-feature-engineering-5d165100b0c3\n",
    "- time indexing recomandations https://stackoverflow.com/questions/49711987/how-do-i-prevent-data-leakage-with-featuretools\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Denormalize into \n",
    "- customer_df:      customer_id (PK), subscription_id (FK), gender, SeniorCitizen, Partner, Dependents, tenure, Churn\n",
    "- services_df:      service_id (PK), service_name\n",
    "- subscription_df:  subscription_id (PK), service_id, customer_id\n",
    "- billing_df:       billing_id, Contract, PaperlessBilling, PaymentMethod, MonthlyCharges, TotalCharges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case of CERTIFICATE_VERIFY_FAILED run Install Certificates.command\n",
    "# see also https://stackoverflow.com/questions/50236117/scraping-ssl-certificate-verify-failed-error-for-http-en-wikipedia-org\n",
    "df = pd.read_csv(filepath_or_buffer=URL_TO_DATA, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert\n",
    "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
    "\n",
    "# generate syntetic time index\n",
    "df[\"ContractStartDate\"] = list(\n",
    "    map(\n",
    "        lambda tenure, dat=BACK_COUNT_DATE: dat - relativedelta(months=-tenure),\n",
    "        df[\"tenure\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "# convert to categoric for pipline processing\n",
    "\n",
    "\n",
    "df[\"customerID\"] = df.index\n",
    "df[\"billingID\"] = [str(uuid4()) for _ in range(df.shape[0])]\n",
    "df[\"subscriptionID\"] = [str(uuid4()) for _ in range(df.shape[0])]\n",
    "\n",
    "# convert to 1/0\n",
    "df[\"Churn\"] = np.where(df[\"Churn\"] == \"Yes\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write nice dataclass to map featertools type, pandas and sklearn type\n",
    "# add this info also\n",
    "\n",
    "CUSTOMERS = {\n",
    "    # \"customerID\",\n",
    "    \"gender\":Boolean,\n",
    "     \"SeniorCitizen\":Boolean,\n",
    "    \"Partner\":Boolean,\n",
    "    \"Dependents\":Boolean,\n",
    "}\n",
    "\n",
    "\n",
    "SUBSCRIPTIONS = {\n",
    "    # \"customerID\",\n",
    "    \"PhoneService\" :Categorical,\n",
    "    \"MultipleLines\":Boolean,\n",
    "    \"InternetService\":Categorical,\n",
    "    \"OnlineSecurity\":Categorical,\n",
    "    \"OnlineBackup\":Categorical,\n",
    "    \"DeviceProtection\":Categorical,\n",
    "    \"TechSupport\":Categorical,\n",
    "    \"StreamingTV\":Categorical,\n",
    "    \"StreamingMovies\":Categorical,\n",
    "}\n",
    "\n",
    "\n",
    "BILLINGS = {\n",
    "    # \"customerID\",\n",
    "    \"tenure\":Double,\n",
    "    \"Contract\":Categorical,\n",
    "    \"PaperlessBilling\":Boolean,\n",
    "    \"PaymentMethod\":Categorical,\n",
    "    \"MonthlyCharges\":Double,\n",
    "    \"TotalCharges\":Double,\n",
    "    # \"Churn\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EntitySetColumns:\n",
    "    new_dataframe_name: str\n",
    "    index: str\n",
    "    additional_columns: list\n",
    "\n",
    "\n",
    "entity_set_columns = {\n",
    "    \"customers\": EntitySetColumns(\n",
    "        index=\"customerID\", new_dataframe_name=None, additional_columns=list(CUSTOMERS.keys())\n",
    "    ),\n",
    "    \"subscriptions\": EntitySetColumns(\n",
    "        index=\"subscriptionID\",\n",
    "        new_dataframe_name=\"subscriptions\",\n",
    "        additional_columns=list(SUBSCRIPTIONS.keys()),\n",
    "    ),\n",
    "    \"billings\": EntitySetColumns(\n",
    "        index=\"billingID\", new_dataframe_name=\"billings\", additional_columns=list(BILLINGS.keys())\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Churn\"]\n",
    "X = df.drop(columns=[\"Churn\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=VALID_SIZE, random_state=RANDOM_STATE\n",
    ")  # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entityset_wrapper(\n",
    "    id: str,\n",
    "    data_frame_name: str, \n",
    "    feature_dataset: pd.DataFrame,\n",
    "    variable_types: dict,\n",
    "    entity_set_columns: dict,\n",
    ") -> ft.EntitySet:\n",
    "    \"\"\"Non generic wrapper for making ft.EntitySet\"\"\"\n",
    "    es = ft.EntitySet(id=id)\n",
    "\n",
    "    es.add_dataframe(\n",
    "        dataframe_name=data_frame_name,\n",
    "        index=entity_set_columns.get(\"customers\").index,\n",
    "        logical_types=variable_types,\n",
    "        dataframe=feature_dataset,\n",
    "    )\n",
    "\n",
    "    es.normalize_dataframe(\n",
    "        base_dataframe_name=data_frame_name,\n",
    "        new_dataframe_name=entity_set_columns.get(\"billings\").new_dataframe_name,\n",
    "        index=entity_set_columns.get(\"billings\").index,\n",
    "        additional_columns=entity_set_columns.get(\"billings\").additional_columns,\n",
    "    )\n",
    "\n",
    "    es.normalize_dataframe(\n",
    "        base_dataframe_name=data_frame_name,\n",
    "        new_dataframe_name=entity_set_columns.get(\"subscriptions\").new_dataframe_name,\n",
    "        index=entity_set_columns.get(\"subscriptions\").index,\n",
    "        additional_columns=entity_set_columns.get(\"subscriptions\").additional_columns,\n",
    "    )\n",
    "\n",
    "    return es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = entityset_wrapper(\n",
    "    id=\"customers_train\",\n",
    "    data_frame_name=\"customers\",\n",
    "    feature_dataset=X_train,\n",
    "    variable_types=CUSTOMERS | SUBSCRIPTIONS | BILLINGS,\n",
    "    entity_set_columns=entity_set_columns,\n",
    ")\n",
    "es.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix, feature_defs = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_dataframe_name=\"customers\",\n",
    "    max_depth=2,\n",
    "    include_cutoff_time=False,\n",
    "    agg_primitives=None,\n",
    "    cutoff_time=None,\n",
    "    instance_ids=None,\n",
    ")\n",
    "\n",
    "feature_matrix_enc, features_enc = ft.encode_features(feature_matrix, feature_defs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "#feature_selector = Pipeline(\n",
    "#    steps=[\n",
    "#        (\"rm_highly_null_features\",         FunctionTransformer(remove_highly_null_features)),\n",
    "#        (\"rm_single_value_features\",        FunctionTransformer(remove_single_value_features)),\n",
    "#    ]\n",
    "#)\n",
    "\n",
    "    #remove_highly_correlated_features,\n",
    "    #remove_highly_null_features,\n",
    "    #remove_single_value_features,\n",
    "\n",
    " #   set(features) - set(new_features)\n",
    "\n",
    "# not necessary\n",
    "#tmp, temp2  = remove_highly_null_features(feature_matrix_enc, features_enc, pct_null_threshold=.90)\n",
    "#set(features_enc) - set(temp2)\n",
    "\n",
    "#feature_matrix_enc_selected, features_enc_selected = remove_highly_correlated_features(feature_matrix_enc, features=features_enc)\n",
    "#set(features_enc) - set(features_enc_selected)\n",
    "\n",
    "\n",
    "feature_matrix_enc_selected, features_enc_selected = remove_highly_null_features(feature_matrix_enc, features=features_enc)\n",
    "set(features_enc) - set(features_enc_selected)\n",
    "\n",
    "fm_selected, f_selected = remove_single_value_features(feature_matrix_enc_selected, features=features_enc_selected)\n",
    "set(features_enc) - set(f_selected)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fmt: on\n",
    "numeric_features_ft = get_cols_by_type(\n",
    "    in_df=fm_selected,\n",
    "    types_to_search=[np.float64, np.int64],\n",
    "    exclude_ids=False,\n",
    ")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features_ft),\n",
    "    ]\n",
    ")\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "clf = Pipeline(\n",
    "    steps=[ (\"preprocessor\", preprocessor), \n",
    "            (\"classifier\", RandomForestClassifier())]  # (\"preprocessor\", preprocessor),\n",
    "            \n",
    ")\n",
    "# fmt: on\n",
    "train_transformed = fm_selected\n",
    "\n",
    "\n",
    "clf.fit(train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_val = entityset_wrapper(\n",
    "    id=\"customers_validation\",\n",
    "    data_frame_name=\"customers\",\n",
    "    feature_dataset=X_val,\n",
    "    variable_types=CUSTOMERS | SUBSCRIPTIONS | BILLINGS,\n",
    "    entity_set_columns=entity_set_columns,\n",
    ")\n",
    "\n",
    "val_transformed = ft.calculate_feature_matrix(f_selected, es_val)\n",
    "\n",
    "\n",
    "\n",
    "es_test = entityset_wrapper(\n",
    "    id=\"customers_test\",\n",
    "    data_frame_name=\"customers\",\n",
    "    feature_dataset=X_test,\n",
    "    variable_types=CUSTOMERS | SUBSCRIPTIONS | BILLINGS,\n",
    "    entity_set_columns=entity_set_columns,\n",
    ")\n",
    "\n",
    "test_transformed = ft.calculate_feature_matrix(f_selected, es_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"model score: %.3f\" % clf.score(val_transformed, y_val))\n",
    "print(\"model score: %.3f\" % clf.score(test_transformed, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "one_hot_enc = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, get_cols_by_type(in_df=X_train, types_to_search=[np.float64])),\n",
    "        (\"onehot\", one_hot_enc,      get_cols_by_type(in_df=X_train, types_to_search=[np.object0, np.object_])),\n",
    "    ]\n",
    ")\n",
    "# fmt: on\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = Pipeline(\n",
    "    # steps=[(\"preprocessor\", preprocessor), (\"classifier\", xgb.XGBClassifier(objective=\"binary:logistic\", random_state=RANDOM_STATE))]\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", RandomForestClassifier())]\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_val, y_val))\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('data-science-playbooks-Yk-1xU1Q-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "919e6aa0d89df1282d444dc7cd808811badc65a732d2c47612a254902fd6721c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
