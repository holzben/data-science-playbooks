{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun with Featurtools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example [featuretools](https://www.featuretools.com/) an python frame for automated feature engineering is used to generate a wide range of features for machine learning. The aim of the Notebook is to show how the framework is used and how it could support ML workflows, but should not be considered as a tutorial on Machine Learning.\n",
    "\n",
    "One of the main benefits of the frame work is the so called deep feature synthesis (dfs), which used relations in the data for automatically generating feature, this could be, obviously depending on your data, features like mean session length, average purchasing price or standard deviation of time since last session. The term deep comes referes to stacking generated features on top of each other. \n",
    "\n",
    "The main building block of Featuretools are feature primiteves and can be represented in two main groups: aggregation and transformation primitive. Like the name indicates, aggregation primitives take related inputs and return a single ountput, similar to  group by aggregations known from sql. Transformation primitives on the other hand are conveting, eg timstamps into data, hour, minutes, seconds etc or calculating differences to certain events. The full list of possible primitives can be found [here](https://primitives.featurelabs.com/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import featuretools as ft\n",
    "\n",
    "from woodwork.logical_types import Categorical, Boolean, Datetime, Double\n",
    "\n",
    "# from featuretools_sklearn_transformer import DFSTransformer => did not work\n",
    "from featuretools.selection import (\n",
    "    remove_highly_correlated_features,\n",
    "    remove_highly_null_features,\n",
    "    remove_single_value_features,\n",
    ")\n",
    "\n",
    "from datetime import datetime\n",
    "from uuid import uuid4\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from typing import List, Any\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "\n",
    "pd.option_context(\"max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/IBM/telco-customer-churn-on-icp4d\n",
    "URL_TO_DATA = \"https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv\"\n",
    "\n",
    "\n",
    "BACK_COUNT_DATE = datetime.fromisoformat(\"2022-01-01\")\n",
    "TEST_SIZE = 0.2\n",
    "VALID_SIZE = 0.25\n",
    "RANDOM_STATE = 42\n",
    "NUMERIC_TRANSFORMER_REPLACEMENT = \"median\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt:off\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=NUMERIC_TRANSFORMER_REPLACEMENT)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "# fmt:on \n",
    "\n",
    "def get_cols_by_type(\n",
    "    in_df: pd.DataFrame, types_to_search: list, exclude_ids: Boolean = True\n",
    ") -> list:\n",
    "    cols = in_df.select_dtypes(include=types_to_search).columns.to_list()\n",
    "\n",
    "    if exclude_ids:\n",
    "        return list(filter(lambda x: not x.endswith(\"ID\"), cols))\n",
    "\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ft titanic https://www.kaggle.com/code/liananapalkova/automated-feature-engineering-for-titanic-dataset/notebook\n",
    "- the dataset https://github.com/IBM/telco-customer-churn-on-icp4d/blob/master/data/Telco-Customer-Churn.csv\n",
    "- titanic https://medium.com/dataexplorations/tool-review-can-featuretools-simplify-the-process-of-feature-engineering-5d165100b0c3\n",
    "- time indexing recomandations https://stackoverflow.com/questions/49711987/how-do-i-prevent-data-leakage-with-featuretools\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Denormalize into \n",
    "- customer_df:      customer_id (PK), subscription_id (FK), gender, SeniorCitizen, Partner, Dependents, tenure, Churn\n",
    "- services_df:      service_id (PK), service_name\n",
    "- subscription_df:  subscription_id (PK), service_id, customer_id\n",
    "- billing_df:       billing_id, Contract, PaperlessBilling, PaymentMethod, MonthlyCharges, TotalCharges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case of CERTIFICATE_VERIFY_FAILED run Install Certificates.command\n",
    "# see also https://stackoverflow.com/questions/50236117/scraping-ssl-certificate-verify-failed-error-for-http-en-wikipedia-org\n",
    "df = pd.read_csv(filepath_or_buffer=URL_TO_DATA, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write nice dataclass to map featertools type, pandas and sklearn type\n",
    "# add this info also\n",
    "\n",
    "CUSTOMERS = {\n",
    "    # \"customerID\",\n",
    "    \"gender\":Boolean,\n",
    "    \"SeniorCitizen\":Boolean,\n",
    "    \"Partner\":Boolean,\n",
    "    \"Dependents\":Boolean,\n",
    "}\n",
    "\n",
    "\n",
    "SUBSCRIPTIONS = {\n",
    "    # \"customerID\",\n",
    "    \"PhoneService\" :Categorical,\n",
    "    \"MultipleLines\":Boolean,\n",
    "    \"InternetService\":Categorical,\n",
    "    \"OnlineSecurity\":Categorical,\n",
    "    \"OnlineBackup\":Categorical,\n",
    "    \"DeviceProtection\":Categorical,\n",
    "    \"TechSupport\":Categorical,\n",
    "    \"StreamingTV\":Categorical,\n",
    "    \"StreamingMovies\":Categorical,\n",
    "}\n",
    "\n",
    "\n",
    "BILLINGS = {\n",
    "    # \"customerID\",\n",
    "    \"tenure\":Double,\n",
    "    \"Contract\":Categorical,\n",
    "    \"PaperlessBilling\":Boolean,\n",
    "    \"PaymentMethod\":Categorical,\n",
    "    \"MonthlyCharges\":Double,\n",
    "    \"TotalCharges\":Double,\n",
    "    # \"Churn\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert\n",
    "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
    "\n",
    "# generate syntetic time index\n",
    "df[\"ContractStartDate\"] = list(\n",
    "    map(\n",
    "        lambda tenure, dat=BACK_COUNT_DATE: dat - relativedelta(months=-tenure),\n",
    "        df[\"tenure\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "# convert to categoric for pipline processing\n",
    "\n",
    "\n",
    "df[\"customerID\"] = df.index\n",
    "df[\"billingID\"] = [str(uuid4()) for _ in range(df.shape[0])]\n",
    "df[\"subscriptionID\"] = [str(uuid4()) for _ in range(df.shape[0])]\n",
    "\n",
    "# convert to 1/0\n",
    "df[\"Churn\"] = np.where(df[\"Churn\"] == \"Yes\", 1, 0)\n",
    "\n",
    "\n",
    "df[\"ShortContract\"] = df['Contract'] == 'Month-to-month'\n",
    "BILLINGS['ShortContract'] = Boolean\n",
    "\n",
    "# remove because it depends on Phone service\n",
    "products = [n for n in list(SUBSCRIPTIONS.keys()) if n != 'MultipleLines']\n",
    "\n",
    "df['TotalProductCount'] = (df[products] != 'No').sum(axis=1)\n",
    "SUBSCRIPTIONS['TotalProductCount'] = Double\n",
    "\n",
    "df['UserCategory'] = pd.cut(x=df['TotalProductCount'], bins=[0, 3, 6, np.Inf], labels=['light', 'mid', 'heavy'])\n",
    "CUSTOMERS['UserCategory'] = Categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EntitySetColumns:\n",
    "    new_dataframe_name: str\n",
    "    index: str\n",
    "    additional_columns: list\n",
    "\n",
    "\n",
    "entity_set_columns = {\n",
    "    \"customers\": EntitySetColumns(\n",
    "        index=\"customerID\", new_dataframe_name=None, additional_columns=list(CUSTOMERS.keys())\n",
    "    ),\n",
    "    \"subscriptions\": EntitySetColumns(\n",
    "        index=\"subscriptionID\",\n",
    "        new_dataframe_name=\"subscriptions\",\n",
    "        additional_columns=list(SUBSCRIPTIONS.keys()),\n",
    "    ),\n",
    "    \"billings\": EntitySetColumns(\n",
    "        index=\"billingID\", new_dataframe_name=\"billings\", additional_columns=list(BILLINGS.keys())\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Churn\"]\n",
    "X = df.drop(columns=[\"Churn\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=VALID_SIZE, random_state=RANDOM_STATE\n",
    ")  # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entityset_wrapper(\n",
    "    id: str,\n",
    "    data_frame_name: str, \n",
    "    feature_dataset: pd.DataFrame,\n",
    "    variable_types: dict,\n",
    "    entity_set_columns: dict,\n",
    ") -> ft.EntitySet:\n",
    "    \"\"\"Non generic wrapper for making ft.EntitySet\"\"\"\n",
    "    es = ft.EntitySet(id=id)\n",
    "\n",
    "    es.add_dataframe(\n",
    "        dataframe_name=data_frame_name,\n",
    "        index=entity_set_columns.get(\"customers\").index,\n",
    "        logical_types=variable_types,\n",
    "        dataframe=feature_dataset,\n",
    "    )\n",
    "\n",
    "    es.normalize_dataframe(\n",
    "        base_dataframe_name=data_frame_name,\n",
    "        new_dataframe_name=entity_set_columns.get(\"billings\").new_dataframe_name,\n",
    "        index=entity_set_columns.get(\"billings\").index,\n",
    "        additional_columns=entity_set_columns.get(\"billings\").additional_columns,\n",
    "    )\n",
    "\n",
    "    es.normalize_dataframe(\n",
    "        base_dataframe_name=data_frame_name,\n",
    "        new_dataframe_name=entity_set_columns.get(\"subscriptions\").new_dataframe_name,\n",
    "        index=entity_set_columns.get(\"subscriptions\").index,\n",
    "        additional_columns=entity_set_columns.get(\"subscriptions\").additional_columns,\n",
    "    )\n",
    "\n",
    "    return es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = entityset_wrapper(\n",
    "    id=\"customers_train\",\n",
    "    data_frame_name=\"customers\",\n",
    "    feature_dataset=X_train,\n",
    "    variable_types=CUSTOMERS | SUBSCRIPTIONS | BILLINGS,\n",
    "    entity_set_columns=entity_set_columns,\n",
    ")\n",
    "es.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix, feature_defs = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_dataframe_name=\"customers\",\n",
    "    max_depth=2,\n",
    "    include_cutoff_time=False,\n",
    "    agg_primitives=None,\n",
    "    cutoff_time=None,\n",
    "    instance_ids=None,\n",
    "    seed_features=None\n",
    ")\n",
    "\n",
    "feature_matrix_enc, features_enc = ft.encode_features(feature_matrix, feature_defs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "#feature_selector = Pipeline(\n",
    "#    steps=[\n",
    "#        (\"rm_highly_null_features\",         FunctionTransformer(remove_highly_null_features)),\n",
    "#        (\"rm_single_value_features\",        FunctionTransformer(remove_single_value_features)),\n",
    "#    ]\n",
    "#)\n",
    "\n",
    "    #remove_highly_correlated_features,\n",
    "    #remove_highly_null_features,\n",
    "    #remove_single_value_features,\n",
    "\n",
    " #   set(features) - set(new_features)\n",
    "\n",
    "# not necessary\n",
    "#tmp, temp2  = remove_highly_null_features(feature_matrix_enc, features_enc, pct_null_threshold=.90)\n",
    "#set(features_enc) - set(temp2)\n",
    "\n",
    "#feature_matrix_enc_selected, features_enc_selected = remove_highly_correlated_features(feature_matrix_enc, features=features_enc)\n",
    "#set(features_enc) - set(features_enc_selected)\n",
    "\n",
    "feature_matrix_enc_selected, features_enc_selected = remove_highly_null_features(feature_matrix_enc, features=features_enc, pct_null_threshold = .85)\n",
    "set(features_enc) - set(features_enc_selected)\n",
    "\n",
    "fm_selected, f_selected = remove_single_value_features(feature_matrix_enc_selected, features=features_enc_selected)\n",
    "set(features_enc) - set(f_selected)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fmt: off\n",
    "numeric_features_ft = get_cols_by_type(\n",
    "    in_df=fm_selected,\n",
    "    types_to_search=[np.float64, np.int64],\n",
    "    exclude_ids=False,\n",
    ")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features_ft),\n",
    "    ], verbose=True, remainder = \"passthrough\"\n",
    ")\n",
    "# fmt: on\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel, VarianceThreshold\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "VARIANCE_THRESHOLD = .8 * (1- .8)\n",
    "\n",
    "#svm.SVC()\n",
    "# fmt: off\n",
    "clf = Pipeline(\n",
    "    steps=[ (\"preprocessor\", preprocessor), \n",
    "            ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l2\", max_iter = 10000))),\n",
    "            ('feture_selecction_variance', VarianceThreshold(threshold=VARIANCE_THRESHOLD)),\n",
    "            (\"classifier\", xgb.XGBClassifier(objective=\"binary:logistic\", random_state=RANDOM_STATE))],\n",
    "            verbose=True\n",
    "            \n",
    ")\n",
    "# fmt: on\n",
    "\n",
    "train_transformed = fm_selected\n",
    "\n",
    "\n",
    "clf.fit(train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_val = entityset_wrapper(\n",
    "    id=\"customers_validation\",\n",
    "    data_frame_name=\"customers\",\n",
    "    feature_dataset=X_val,\n",
    "    variable_types=CUSTOMERS | SUBSCRIPTIONS | BILLINGS,\n",
    "    entity_set_columns=entity_set_columns,\n",
    ")\n",
    "\n",
    "val_transformed = ft.calculate_feature_matrix(f_selected, es_val)\n",
    "\n",
    "\n",
    "\n",
    "es_test = entityset_wrapper(\n",
    "    id=\"customers_test\",\n",
    "    data_frame_name=\"customers\",\n",
    "    feature_dataset=X_test,\n",
    "    variable_types=CUSTOMERS | SUBSCRIPTIONS | BILLINGS,\n",
    "    entity_set_columns=entity_set_columns,\n",
    ")\n",
    "\n",
    "test_transformed = ft.calculate_feature_matrix(f_selected, es_test)\n",
    "\n",
    "\n",
    "\n",
    "print(\"model score: %.3f\" % clf.score(val_transformed, y_val))\n",
    "print(\"model score: %.3f\" % clf.score(test_transformed, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "one_hot_enc = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "preprocessor_bm = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, get_cols_by_type(in_df=X_train, types_to_search=[np.float64])),\n",
    "        (\"onehot\", one_hot_enc,      get_cols_by_type(in_df=X_train, types_to_search=[np.object0, np.object_, 'category', 'bool'])),\n",
    "    ]\n",
    ")\n",
    "# fmt: on\n",
    "preprocessor_bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_bm = Pipeline(\n",
    "     steps=[(\"preprocessor\", preprocessor_bm), (\"classifier\", xgb.XGBClassifier(objective=\"binary:logistic\", random_state=RANDOM_STATE))]\n",
    "   # steps=[(\"preprocessor\", preprocessor), (\"classifier\", RandomForestClassifier())]\n",
    ")\n",
    "\n",
    "clf_bm.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf_bm.score(X_val, y_val))\n",
    "print(\"model score: %.3f\" % clf_bm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect_data = Pipeline(steps=[(\"preprocessor\", preprocessor)])\n",
    "\n",
    "#df_train_ft = clf.named_steps[\"preprocessor\"].fit_transform(train_transformed)\n",
    "df_train_ft = clf.named_steps[\"feture_selecction_variance\"].fit_transform(train_transformed)\n",
    "df_train_normal = clf_bm.named_steps[\"preprocessor\"].fit_transform(X_train)\n",
    "\n",
    "#72\n",
    "\n",
    "print(df_train_ft.shape)\n",
    "print(df_train_normal.shape)\n",
    "\n",
    "\n",
    "fm_selected.shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cols_by_type(in_df=X_train, types_to_search=[np.float64])\n",
    "get_cols_by_type(in_df=X_train, types_to_search=[np.object0, np.object_])\n",
    "in_df=X_train\n",
    "types_to_search=[np.object0, np.object_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_train_normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_transformed.shape)\n",
    "\n",
    "df_train_ft = clf.named_steps[\"preprocessor\"].fit_transform(train_transformed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(df['PhoneService'] == 'Yes')\n",
    "\n",
    "#(df['InternetService'] == 'Yes')\n",
    "#df['InternetService'].unique()\n",
    "\n",
    "\n",
    "products = [n for n in list(SUBSCRIPTIONS.keys()) if n != 'MultipleLines']\n",
    "\n",
    "res = (df[products] != 'No').sum(axis=1)\n",
    "\n",
    "\n",
    "pd.cut(x=(df[products] != 'No').sum(axis=1), bins=[0, 3, 6, np.Inf], labels=['light', 'mid', 'heavy']).value_counts()\n",
    "\n",
    "\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDED_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('data-science-playbooks-BCpveUor-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bee2308daca9d7493daa3ca6c18986251e2646dc5a84293a86d7cb61b114a88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
