{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas._config.config.option_context at 0x107800190>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import featuretools as ft\n",
    "\n",
    "from woodwork.logical_types import Categorical, Boolean, Datetime, Double\n",
    "\n",
    "# from featuretools_sklearn_transformer import DFSTransformer => did not work\n",
    "from featuretools.selection import (\n",
    "    remove_highly_correlated_features,\n",
    "    remove_highly_null_features,\n",
    "    remove_single_value_features,\n",
    ")\n",
    "\n",
    "from datetime import datetime\n",
    "from uuid import uuid4\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from typing import List, Any\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "\n",
    "pd.option_context(\"max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/IBM/telco-customer-churn-on-icp4d\n",
    "URL_TO_DATA = \"https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv\"\n",
    "\n",
    "\n",
    "BACK_COUNT_DATE = datetime.fromisoformat(\"2022-01-01\")\n",
    "TEST_SIZE = 0.2\n",
    "VALID_SIZE = 0.25\n",
    "RANDOM_STATE = 42\n",
    "NUMERIC_TRANSFORMER_REPLACEMENT = \"median\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"imputer\",\n",
    "            SimpleImputer(\n",
    "                missing_values=np.nan, strategy=NUMERIC_TRANSFORMER_REPLACEMENT\n",
    "            ),\n",
    "        ),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def get_cols_by_type(\n",
    "    in_df: pd.DataFrame, types_to_search: list, exclude_ids: Boolean = True\n",
    ") -> list:\n",
    "    cols = in_df.select_dtypes(include=types_to_search).columns.to_list()\n",
    "\n",
    "    if exclude_ids:\n",
    "        return list(filter(lambda x: not x.endswith(\"ID\"), cols))\n",
    "\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ft titanic https://www.kaggle.com/code/liananapalkova/automated-feature-engineering-for-titanic-dataset/notebook\n",
    "- the dataset https://github.com/IBM/telco-customer-churn-on-icp4d/blob/master/data/Telco-Customer-Churn.csv\n",
    "- titanic https://medium.com/dataexplorations/tool-review-can-featuretools-simplify-the-process-of-feature-engineering-5d165100b0c3\n",
    "- time indexing recomandations https://stackoverflow.com/questions/49711987/how-do-i-prevent-data-leakage-with-featuretools\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Denormalize into \n",
    "- customer_df:      customer_id (PK), subscription_id (FK), gender, SeniorCitizen, Partner, Dependents, tenure, Churn\n",
    "- services_df:      service_id (PK), service_name\n",
    "- subscription_df:  subscription_id (PK), service_id, customer_id\n",
    "- billing_df:       billing_id, Contract, PaperlessBilling, PaymentMethod, MonthlyCharges, TotalCharges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case of CERTIFICATE_VERIFY_FAILED run Install Certificates.command\n",
    "# see also https://stackoverflow.com/questions/50236117/scraping-ssl-certificate-verify-failed-error-for-http-en-wikipedia-org\n",
    "df = pd.read_csv(filepath_or_buffer=URL_TO_DATA, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sh/70_qf54934gg__vq6r1j7pww0000gn/T/ipykernel_8565/2342901228.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# convert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TotalCharges\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TotalCharges\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"coerce\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# generate syntetic time index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m df[\"ContractStartDate\"] = list(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# convert\n",
    "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
    "\n",
    "# generate syntetic time index\n",
    "df[\"ContractStartDate\"] = list(\n",
    "    map(\n",
    "        lambda tenure, dat=BACK_COUNT_DATE: dat - relativedelta(months=-tenure),\n",
    "        df[\"tenure\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "# convert to categoric for pipline processing\n",
    "\n",
    "\n",
    "df[\"customerID\"] = df.index\n",
    "df[\"billingID\"] = [str(uuid4()) for _ in range(df.shape[0])]\n",
    "df[\"subscriptionID\"] = [str(uuid4()) for _ in range(df.shape[0])]\n",
    "\n",
    "# convert to 1/0\n",
    "df[\"Churn\"] = np.where(df[\"Churn\"] == \"Yes\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write nice dataclass to map featertools type, pandas and sklearn type\n",
    "# add this info also\n",
    "\n",
    "CUSTOMERS = [\n",
    "    # \"customerID\",\n",
    "    \"gender\",\n",
    "    \"SeniorCitizen\",\n",
    "    \"Partner\",\n",
    "    \"Dependents\",\n",
    "]\n",
    "\n",
    "\n",
    "SUBSCRIPTIONS = [\n",
    "    # \"customerID\",\n",
    "    \"PhoneService\",\n",
    "    \"MultipleLines\",\n",
    "    \"InternetService\",\n",
    "    \"OnlineSecurity\",\n",
    "    \"OnlineBackup\",\n",
    "    \"DeviceProtection\",\n",
    "    \"TechSupport\",\n",
    "    \"StreamingTV\",\n",
    "    \"StreamingMovies\",\n",
    "]\n",
    "\n",
    "\n",
    "BILLINGS = [\n",
    "    # \"customerID\",\n",
    "    \"tenure\",\n",
    "    \"Contract\",\n",
    "    \"PaperlessBilling\",\n",
    "    \"PaymentMethod\",\n",
    "    \"MonthlyCharges\",\n",
    "    \"TotalCharges\",\n",
    "    # \"Churn\",\n",
    "]\n",
    "\n",
    "\n",
    "class EntitiesEnum(Enum):\n",
    "    cu = \"customer'\"\n",
    "    BILLINGS = \"billings\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EntitySetColumns:\n",
    "    new_dataframe_name: str\n",
    "    index: str\n",
    "    additional_columns: list\n",
    "\n",
    "\n",
    "entity_set_columns = {\n",
    "    \"customers\": EntitySetColumns(\n",
    "        index=\"customerID\", new_dataframe_name=None, additional_columns=CUSTOMERS\n",
    "    ),\n",
    "    \"subscriptions\": EntitySetColumns(\n",
    "        index=\"subscriptionID\",\n",
    "        new_dataframe_name=\"subscriptions\",\n",
    "        additional_columns=SUBSCRIPTIONS,\n",
    "    ),\n",
    "    \"billings\": EntitySetColumns(\n",
    "        index=\"billingID\", new_dataframe_name=\"billings\", additional_columns=BILLINGS\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Churn\"]\n",
    "X = df.drop(columns=[\"Churn\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=VALID_SIZE, random_state=RANDOM_STATE\n",
    ")  # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_types = {\n",
    "    \"gender\": Boolean,\n",
    "    \"SeniorCitizen\": Boolean,\n",
    "    \"Partner\": Boolean,\n",
    "    \"Dependents\": Boolean,\n",
    "    \"PhoneService\": Boolean,\n",
    "    \"PaperlessBilling\": Boolean,\n",
    "    \"MultipleLines\": Categorical,\n",
    "    \"InternetService\": Categorical,\n",
    "    \"OnlineSecurity\": Categorical,\n",
    "    \"OnlineBackup\": Categorical,\n",
    "    \"DeviceProtection\": Categorical,\n",
    "    \"TechSupport\": Categorical,\n",
    "    \"StreamingTV\": Categorical,\n",
    "    \"StreamingMovies\": Categorical,\n",
    "    \"Contract\": Categorical,\n",
    "    \"PaymentMethod\": Categorical,\n",
    "    \"tenure\": Double,\n",
    "    \"MonthlyCharges\": Double,\n",
    "    \"TotalCharges\": Double,\n",
    "    \"subscriptionID\": Categorical,\n",
    "    \"customerID\": Categorical,\n",
    "    \"billingID\": Categorical,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entityset_wrapper(\n",
    "    id: str,\n",
    "    feature_dataset: pd.DataFrame,\n",
    "    variable_types: dict,\n",
    "    entity_set_columns: dict,\n",
    ") -> ft.EntitySet:\n",
    "    \"\"\"Non generic wrapper for making ft.EntitySet\"\"\"\n",
    "    es = ft.EntitySet(id=id)\n",
    "\n",
    "    es.add_dataframe(\n",
    "        dataframe_name=\"customers\",\n",
    "        index=entity_set_columns.get(\"customers\").index,\n",
    "        logical_types=variable_types,\n",
    "        dataframe=feature_dataset,\n",
    "    )\n",
    "\n",
    "    es.normalize_dataframe(\n",
    "        base_dataframe_name=\"customers\",\n",
    "        new_dataframe_name=entity_set_columns.get(\"billings\").new_dataframe_name,\n",
    "        index=entity_set_columns.get(\"billings\").index,\n",
    "        additional_columns=entity_set_columns.get(\"billings\").additional_columns,\n",
    "    )\n",
    "\n",
    "    es.normalize_dataframe(\n",
    "        base_dataframe_name=\"customers\",\n",
    "        new_dataframe_name=entity_set_columns.get(\"subscriptions\").new_dataframe_name,\n",
    "        index=entity_set_columns.get(\"subscriptions\").index,\n",
    "        additional_columns=entity_set_columns.get(\"subscriptions\").additional_columns,\n",
    "    )\n",
    "\n",
    "    return es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = entityset_wrapper(\n",
    "    id=\"customers_train\",\n",
    "    feature_dataset=X_train,\n",
    "    variable_types=variable_types,\n",
    "    entity_set_columns=entity_set_columns,\n",
    ")\n",
    "es.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es = ft.EntitySet(id=\"customer_churn\")\n",
    "\n",
    "# es.add_dataframe(\n",
    "#     dataframe_name=\"customers\",\n",
    "#     index=\"customerID\",\n",
    "#     # time_index=\"ContractStartDate\",\n",
    "#     logical_types=variable_types,\n",
    "#     dataframe=X_train,\n",
    "# )\n",
    "\n",
    "# es.normalize_dataframe(\n",
    "#     base_dataframe_name=\"customers\",\n",
    "#     new_dataframe_name=\"subscriptions\",\n",
    "#     index=\"subscriptionID\",\n",
    "#     additional_columns=SUBSCRIPTIONS,\n",
    "# )\n",
    "\n",
    "# es.normalize_dataframe(\n",
    "#     base_dataframe_name=\"customers\",\n",
    "#     new_dataframe_name=\"billings\",\n",
    "#     index=\"billingID\",\n",
    "#     additional_columns=BILLING,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix, feature_defs = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_dataframe_name=\"customers\",\n",
    "    max_depth=2,\n",
    "    include_cutoff_time=False,\n",
    "    agg_primitives=None,\n",
    "    cutoff_time=None,\n",
    "    instance_ids=None,\n",
    ")\n",
    "\n",
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_enc, features_enc = ft.encode_features(feature_matrix, feature_defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = feature_matrix_enc.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "feature_selector = Pipeline(\n",
    "    steps=[\n",
    "      #  (\"rm_highly_correlated_features\",   FunctionTransformer(remove_highly_correlated_features)),\n",
    "      #  (\"rm_highly_null_features\",         FunctionTransformer(remove_highly_null_features)),\n",
    "       # (\"rm_single_value_features\",        FunctionTransformer(fun)),\n",
    "    ]\n",
    ")\n",
    "# fmt: on\n",
    "numeric_features_ft = get_cols_by_type(\n",
    "    in_df=feature_matrix_enc,\n",
    "    types_to_search=[np.float64, np.int64],\n",
    "    exclude_ids=False,\n",
    ")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # (\"feature_selector\", feature_selector, all_features),\n",
    "        (\"num\", numeric_transformer, numeric_features_ft),\n",
    "        # ('test', FunctionTransformer(remove_single_value_features), all_features),\n",
    "    ]\n",
    ")\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "#preprocessor = ColumnTransformer(\n",
    "#    transformers=[\n",
    "#    (\"num\", numeric_transformer, get_categoric_cols(in_df=X_train, types_to_search=[\"dtype('float64')\", \"dtype('float64')\"]))\n",
    "#    ]\n",
    "#)\n",
    "\n",
    "\n",
    "clf = Pipeline(\n",
    "    # steps=[(\"preprocessor\", preprocessor), (\"classifier\", xgb.XGBClassifier(objective=\"binary:logistic\", random_state=RANDOM_STATE))]\n",
    "    steps=[ (\"preprocessor\", preprocessor), \n",
    "            (\"classifier\", RandomForestClassifier())]  # (\"preprocessor\", preprocessor),\n",
    "            \n",
    ")\n",
    "# fmt: on\n",
    "clf.fit(feature_matrix_enc, y_train)\n",
    "# print(\"model score: %.3f\" % clf.score(X_val, y_val))\n",
    "# print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "one_hot_enc = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, get_cols_by_type(in_df=X_train, types_to_search=[np.float64])),\n",
    "        (\"onehot\", one_hot_enc,      get_cols_by_type(in_df=X_train, types_to_search=[np.object0, np.object_])),\n",
    "    ]\n",
    ")\n",
    "# fmt: on\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = Pipeline(\n",
    "    # steps=[(\"preprocessor\", preprocessor), (\"classifier\", xgb.XGBClassifier(objective=\"binary:logistic\", random_state=RANDOM_STATE))]\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", RandomForestClassifier())]\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_val, y_val))\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test pre commit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('data-science-playbooks-Yk-1xU1Q-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "919e6aa0d89df1282d444dc7cd808811badc65a732d2c47612a254902fd6721c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
